{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a34bfe",
   "metadata": {},
   "source": [
    "# Thư viện "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d916766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    (262, XGBClassifier(n_estimators = 600, max_depth = 60, learning_rate = 0.001)), \n",
    "    (263, XGBClassifier(n_estimators = 600, max_depth = 60, learning_rate = 0.01)), \n",
    "    (264, XGBClassifier(n_estimators = 600, max_depth = 60, learning_rate = 0.1)), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    (265, XGBClassifier(n_estimators = 600, max_depth = 60, learning_rate = 0.1)), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d379301",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    \n",
    "    (8, LogisticRegression(warm_start = True, C = 1, max_iter = 1000)), \n",
    "    (9, LogisticRegression(warm_start = True, C = 0.1, max_iter = 1000)), \n",
    "    (10, LogisticRegression(warm_start = True, C = 0.01, max_iter = 1000)), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8a6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "(11, LogisticRegression(warm_start = True, penalty='elasticnet', solver='saga', l1_ratio = 0.8, C = 100, max_iter = 500)), \n",
    "(12, LogisticRegression(warm_start = True, penalty='elasticnet', solver='saga', l1_ratio = 0.3, C = 100, max_iter = 500)), \n",
    "(13, LogisticRegression(warm_start = True, penalty='elasticnet', solver='saga', l1_ratio = 0.5, C = 100, max_iter = 500)), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80906a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(11, LogisticRegression(warm_start = True, penalty='elasticnet', solver='saga', l1_ratio = 0.8, C = 100, max_iter = 100)), \n",
    "(12, LogisticRegression(warm_start = True, penalty='elasticnet', solver='saga', l1_ratio = 0.8, C = 200, max_iter = 100)), \n",
    "(13, LogisticRegression(warm_start = True, penalty='elasticnet', solver='saga', l1_ratio = 0.8, C = 300, max_iter = 100)), \n",
    "(14, LogisticRegression(warm_start = True, penalty='elasticnet', solver='saga', l1_ratio = 0.8, C = 400, max_iter = 100)), \n",
    "(15, LogisticRegression(warm_start = True, penalty='elasticnet', solver='saga', l1_ratio = 0.8, C = 500, max_iter = 100)), \n",
    "(16, LogisticRegression(warm_start = True, penalty='elasticnet', solver='saga', l1_ratio = 0.8, C = 600, max_iter = 100)), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a0e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hướng giảm l1_ratio\n",
    "(17, LogisticRegression(warm_start = True, penalty='elasticnet', solver='saga', l1_ratio = 0.5, C = 100, max_iter = 100)), \n",
    "(18, LogisticRegression(warm_start = True, penalty='elasticnet', solver='saga', l1_ratio = 0.3, C = 100, max_iter = 100)), \n",
    "(19, LogisticRegression(warm_start = True, penalty='elasticnet', solver='saga', l1_ratio = 0.1, C = 100, max_iter = 100)), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db61d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree \n",
    "# Hướng tăng max_depth\n",
    "(20, DecisionTreeClassifier( max_depth = 10)), \n",
    "(21, DecisionTreeClassifier( max_depth = 20)), \n",
    "(22, DecisionTreeClassifier( max_depth = 30)), \n",
    "(23, DecisionTreeClassifier( max_depth = 40)), \n",
    "(24, DecisionTreeClassifier( max_depth = 50)), \n",
    "(25, DecisionTreeClassifier( max_depth = 60)), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af45ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier\n",
    "# Hướng tăng max_depth\n",
    "(26, RandomForestClassifier(n_estimators = 100,  max_depth = 10)), \n",
    "(27, RandomForestClassifier(n_estimators = 100,  max_depth = 20)), \n",
    "(28, RandomForestClassifier(n_estimators = 100,  max_depth = 30)), \n",
    "(29, RandomForestClassifier(n_estimators = 100,  max_depth = 40)), \n",
    "(30, RandomForestClassifier(n_estimators = 100,  max_depth = 50)), \n",
    "(31, RandomForestClassifier(n_estimators = 100,  max_depth = 60)), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b52daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hướng tăng n_estimators\n",
    "(32, RandomForestClassifier(n_estimators = 100,  max_depth = 50)), \n",
    "(33, RandomForestClassifier(n_estimators = 300,  max_depth = 50)), \n",
    "(34, RandomForestClassifier(n_estimators = 500,  max_depth = 50)), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hướng giảm max_samples\n",
    "(35, RandomForestClassifier(n_estimators = 300,  max_depth = 50, max_samples=0.9)), \n",
    "(36, RandomForestClassifier(n_estimators = 300,  max_depth = 50, max_samples=0.7)), \n",
    "(37, RandomForestClassifier(n_estimators = 300,  max_depth = 50, max_samples=0.5)), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f5a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExtraTreesClassifier\n",
    "# Hướng tăng max_depth\n",
    "(38, ExtraTreesClassifier(n_estimators = 100,  max_depth = 10)), \n",
    "(39, ExtraTreesClassifier(n_estimators = 100,  max_depth = 20)), \n",
    "(40, ExtraTreesClassifier(n_estimators = 100,  max_depth = 30)), \n",
    "(41, ExtraTreesClassifier(n_estimators = 100,  max_depth = 40)), \n",
    "(42, ExtraTreesClassifier(n_estimators = 100,  max_depth = 50)), \n",
    "(43, ExtraTreesClassifier(n_estimators = 100,  max_depth = 60)), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3f1a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier\n",
    "# Hướng tăng max_depth\n",
    "(44, XGBClassifier(n_estimators = 100,  max_depth = 10, learning_rate = 0.1)), \n",
    "(45, XGBClassifier(n_estimators = 100,  max_depth = 20, learning_rate = 0.1)), \n",
    "(46, XGBClassifier(n_estimators = 100,  max_depth = 30, learning_rate = 0.1)), \n",
    "(47, XGBClassifier(n_estimators = 100,  max_depth = 40, learning_rate = 0.1)), \n",
    "(48, XGBClassifier(n_estimators = 100,  max_depth = 50, learning_rate = 0.1)), \n",
    "(48, XGBClassifier(n_estimators = 100,  max_depth = 60, learning_rate = 0.1)), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55019d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Hướng giảm n_estimators\n",
    "    (50, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.1)),\n",
    "    (51, XGBClassifier(n_estimators = 60,  max_depth = 60, learning_rate = 0.1)),\n",
    "    (52, XGBClassifier(n_estimators = 40,  max_depth = 60, learning_rate = 0.1)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5066f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hướng giảm learning_rate\n",
    "(53, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.05)),\n",
    "(54, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.01)),\n",
    "(55, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.005)),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a4aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hướng tăng reg_alpha\n",
    "(56, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.1, reg_alpha = 0.1)), \n",
    "(57, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.1, reg_alpha = 0.5)), \n",
    "(58, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.1, reg_alpha = 1)), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c203613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hướng tăng reg_lambda\n",
    "(59, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.1, reg_alpha = 1, reg_lambda=0.1)), \n",
    "(60, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.1, reg_alpha = 1, reg_lambda=0.5)), \n",
    "(61, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.1, reg_alpha = 1, reg_lambda=1)), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f03500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hướng tăng reg_alpha\n",
    "(62, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.1, reg_alpha = 3)), \n",
    "(63, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.1, reg_alpha = 5)), \n",
    "(64, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.1, reg_alpha = 7)), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f6410",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_after_feature_transformer = [\n",
    "    PolynomialFeatures(degree = 2, include_bias = False), \n",
    "    MinMaxScaler(), \n",
    "    PCA(n_components = ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e7fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hướng cho subsample = 0.7\n",
    "(65, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.1, reg_alpha = 3, subsample = 0.7)), \n",
    "(66, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.1, reg_alpha = 5, subsample = 0.7)), \n",
    "(67, XGBClassifier(n_estimators = 80,  max_depth = 60, learning_rate = 0.1, reg_alpha = 7, subsample = 0.7)), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78deca60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed shape: (500, 594)\n"
     ]
    }
   ],
   "source": [
    "from math import comb  # Python 3.8+\n",
    "\n",
    "n_features = 32\n",
    "degree = 2\n",
    "total_features = sum(comb(n_features + i, i) for i in range(1, degree + 1))\n",
    "\n",
    "print(f\"Transformed shape: (500, {total_features})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360501c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1, [\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "]), \n",
    "(2, [\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "]), \n",
    "(3, [\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e1381",
   "metadata": {},
   "outputs": [],
   "source": [
    "(4, [\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20413c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(5, [\n",
    "    Dense(30, activation='relu'),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1bd1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_after_feature_transformer = [\n",
    "    PolynomialFeatures(degree=2, include_bias =False), \n",
    "    PCA(n_components = 100), \n",
    "    MinMaxScaler(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09492940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "# Hướng tăng C\n",
    "(1, LogisticRegression(warm_start=True, C = 1)), \n",
    "(2, LogisticRegression(warm_start=True, C = 10)), \n",
    "(3, LogisticRegression(warm_start=True, C = 100)), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7749c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1, [\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c454dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e4e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier\n",
    "# Tăng max_depth\n",
    "(4, XGBClassifier(n_estimators = 100, max_depth=10)), \n",
    "(5, XGBClassifier(n_estimators = 100, max_depth=20)), \n",
    "(6, XGBClassifier(n_estimators = 100, max_depth=30)), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37848cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tăng max_depth\n",
    "(7, XGBClassifier(subsample=0.7,n_estimators = 100, max_depth=10, learning_rate = 0.1)), \n",
    "(8, XGBClassifier(subsample=0.7,n_estimators = 100, max_depth=20, learning_rate = 0.1)), \n",
    "(9, XGBClassifier(subsample=0.7,n_estimators = 100, max_depth=30, learning_rate = 0.1)), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseResidualConnection(layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.BatchNormalization = layers.BatchNormalization()\n",
    "        self.Dense1 = layers.Dense(self.units, activation = 'relu')\n",
    "        self.Dense2 = layers.Dense(self.units, activation = 'relu')\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        residual = x\n",
    "\n",
    "        # Xử lí x \n",
    "        x = self.BatchNormalization(x)\n",
    "        x = self.Dense1(x)\n",
    "\n",
    "        # Xử lí residual\n",
    "        residual = self.Dense2(residual)\n",
    "\n",
    "        # Apply residual connection\n",
    "        x = layers.add([x, residual])\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        # Trả về cấu hình của lớp tùy chỉnh\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"units\": self.units,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Giải mã lại lớp từ cấu hình\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef723cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "(2, [\n",
    "    DenseResidualConnection(64, activation='relu'),\n",
    "    DenseResidualConnection(32, activation='relu'),\n",
    "    DenseResidualConnection(16, activation='relu'),\n",
    "    DenseResidualConnection(8, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a790342",
   "metadata": {},
   "outputs": [],
   "source": [
    " (2, [\n",
    "    DenseResidualConnection(units = 64),\n",
    "    DenseResidualConnection(units = 32),\n",
    "    DenseResidualConnection(units = 16),\n",
    "    DenseResidualConnection(units = 8),\n",
    "    Dense(3, activation='softmax')\n",
    "]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "(3, [\n",
    "    DoubleDenseResidualConnection(64, activation='relu'),\n",
    "    DoubleDenseResidualConnection(32, activation='relu'),\n",
    "    DoubleDenseResidualConnection(16, activation='relu'),\n",
    "    DoubleDenseResidualConnection(8, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "518d781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mylib import myfuncs, stringToObjectConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263e2919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yaml file: demo.yaml loaded successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CustomStackingClassifier(estimators=[LogisticRegression(C=0.1),\n",
       "                                     GaussianNB(var_smoothing=1e-08),\n",
       "                                     SGDClassifier(alpha=10, loss=&#x27;log_loss&#x27;)],\n",
       "                         final_estimator=LogisticRegression(C=0.1),\n",
       "                         weights=BoxList([1, 2, 3]))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomStackingClassifier</label><div class=\"sk-toggleable__content\"><pre>CustomStackingClassifier(estimators=[LogisticRegression(C=0.1),\n",
       "                                     GaussianNB(var_smoothing=1e-08),\n",
       "                                     SGDClassifier(alpha=10, loss=&#x27;log_loss&#x27;)],\n",
       "                         final_estimator=LogisticRegression(C=0.1),\n",
       "                         weights=BoxList([1, 2, 3]))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">final_estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "CustomStackingClassifier(estimators=[LogisticRegression(C=0.1),\n",
       "                                     GaussianNB(var_smoothing=1e-08),\n",
       "                                     SGDClassifier(alpha=10, loss='log_loss')],\n",
       "                         final_estimator=LogisticRegression(C=0.1),\n",
       "                         weights=BoxList([1, 2, 3]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_yaml = myfuncs.read_yaml(\"demo.yaml\")\n",
    "models_yaml = models_yaml.models\n",
    "\n",
    "models_yaml\n",
    "\n",
    "models = [stringToObjectConverter.convert_MLmodel_yaml_to_object(model) for model in models_yaml]\n",
    "\n",
    "models[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f78e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ab\n",
       "1    ab\n",
       "2    c1\n",
       "3     d\n",
       "4    ab\n",
       "5    c1\n",
       "6     d\n",
       "dtype: category\n",
       "Categories (3, string): [ab, c1, d]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Mylib import myfuncs \n",
    "import pandas as pd\n",
    "\n",
    "a = pd.Series(['a', 'b', 'c', 'd', 'b', 'c', 'd'])\n",
    "\n",
    "replace_value_list = [\n",
    "    [['a', 'b'], 'ab'],\n",
    "    [['c'], 'c1'],\n",
    "]\n",
    "\n",
    "a = myfuncs.replace_in_category_series_33(a, replace_value_list)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierEvaluator:\n",
    "    \"\"\"Đánh giá classifier trong Deep learning model\n",
    "\n",
    "    Args:\n",
    "        model (_type_): _description_\n",
    "        class_names (_type_): _description_\n",
    "        train_ds (_type_): _description_\n",
    "        val_ds (_type_, optional): Nếu không có, tức là chỉ đánh giá trên 1 tập thôi (đánh giá cho tập test). Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, class_names, train_ds, val_ds=None):\n",
    "        self.model = model\n",
    "        self.class_names = class_names\n",
    "        self.train_ds = train_ds\n",
    "        self.val_ds = val_ds\n",
    "\n",
    "    def evaluate_train_classifier(self):\n",
    "        train_target_data, train_pred = tf_myfuncs.get_full_target_and_pred_for_DLmodel(\n",
    "            self.model, self.train_ds\n",
    "        )\n",
    "        train_pred = [int(item) for item in train_pred]\n",
    "        train_target_data = [int(item) for item in train_target_data]\n",
    "\n",
    "        val_target_data, val_pred = tf_myfuncs.get_full_target_and_pred_for_DLmodel(\n",
    "            self.model, self.val_ds\n",
    "        )\n",
    "        val_pred = [int(item) for item in val_pred]\n",
    "        val_target_data = [int(item) for item in val_target_data]\n",
    "\n",
    "        # Accuracy\n",
    "        train_accuracy = metrics.accuracy_score(train_target_data, train_pred)\n",
    "        val_accuracy = metrics.accuracy_score(val_target_data, val_pred)\n",
    "\n",
    "        # Classification report\n",
    "        class_names = np.asarray(self.class_names)\n",
    "        named_train_target_data = class_names[train_target_data]\n",
    "        named_train_pred = class_names[train_pred]\n",
    "        named_val_target_data = class_names[val_target_data]\n",
    "        named_val_pred = class_names[val_pred]\n",
    "\n",
    "        train_classification_report = metrics.classification_report(\n",
    "            named_train_target_data, named_train_pred\n",
    "        )\n",
    "        val_classification_report = metrics.classification_report(\n",
    "            named_val_target_data, named_val_pred\n",
    "        )\n",
    "\n",
    "        # Confusion matrix\n",
    "        train_confusion_matrix = metrics.confusion_matrix(\n",
    "            named_train_target_data, named_train_pred, labels=class_names\n",
    "        )\n",
    "        np.fill_diagonal(train_confusion_matrix, 0)\n",
    "        train_confusion_matrix = myfuncs.get_heatmap_for_confusion_matrix_30(\n",
    "            train_confusion_matrix, class_names\n",
    "        )\n",
    "\n",
    "        val_confusion_matrix = metrics.confusion_matrix(\n",
    "            named_val_target_data, named_val_pred, labels=class_names\n",
    "        )\n",
    "        np.fill_diagonal(val_confusion_matrix, 0)\n",
    "        val_confusion_matrix = myfuncs.get_heatmap_for_confusion_matrix_30(\n",
    "            val_confusion_matrix, class_names\n",
    "        )\n",
    "\n",
    "        model_results_text = f\"Train accuracy: {train_accuracy}\\n\"\n",
    "        model_results_text += f\"Val accuracy: {val_accuracy}\\n\"\n",
    "        model_results_text += (\n",
    "            f\"Train classification_report: \\n{train_classification_report}\\n\"\n",
    "        )\n",
    "        model_results_text += (\n",
    "            f\"Val classification_report: \\n{val_classification_report}\"\n",
    "        )\n",
    "\n",
    "        return model_results_text, train_confusion_matrix, val_confusion_matrix\n",
    "\n",
    "    def evaluate_test_classifier(self):\n",
    "        test_target_data, test_pred = tf_myfuncs.get_full_target_and_pred_for_DLmodel(\n",
    "            self.model, self.train_ds\n",
    "        )\n",
    "        test_pred = [int(item) for item in test_pred]\n",
    "        test_target_data = [int(item) for item in test_target_data]\n",
    "\n",
    "        # Accuracy\n",
    "        test_accuracy = metrics.accuracy_score(test_target_data, test_pred)\n",
    "\n",
    "        # Classification report\n",
    "        class_names = np.asarray(self.class_names)\n",
    "        named_test_target_data = class_names[test_target_data]\n",
    "        named_test_pred = class_names[test_pred]\n",
    "\n",
    "        test_classification_report = metrics.classification_report(\n",
    "            named_test_target_data, named_test_pred\n",
    "        )\n",
    "\n",
    "        # Confusion matrix\n",
    "        test_confusion_matrix = metrics.confusion_matrix(\n",
    "            named_test_target_data, named_test_pred, labels=class_names\n",
    "        )\n",
    "        np.fill_diagonal(test_confusion_matrix, 0)\n",
    "        test_confusion_matrix = myfuncs.get_heatmap_for_confusion_matrix_30(\n",
    "            test_confusion_matrix, class_names\n",
    "        )\n",
    "\n",
    "        model_results_text = f\"Test accuracy: {test_accuracy}\\n\"\n",
    "        model_results_text += (\n",
    "            f\"Test classification_report: \\n{test_classification_report}\\n\"\n",
    "        )\n",
    "\n",
    "        return model_results_text, test_confusion_matrix\n",
    "\n",
    "    def evaluate(self):\n",
    "        return (\n",
    "            self.evaluate_train_classifier()\n",
    "            if self.val_ds is not None\n",
    "            else self.evaluate_test_classifier()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = df_train[feature_col]\n",
    "targets_col = df_train[target_col]\n",
    "\n",
    "features_col = features_col.apply(lambda x: np.asarray(x))\n",
    "print(f\"Shape của phần tử đầu tiên: {features_col[0].shape}\")\n",
    "\n",
    "# Get các phần tử có shape khác (10, 128)\n",
    "features_col_shape_ne_10_128 = features_col[features_col.apply(lambda x: x.shape != (10, 128))]\n",
    "features_col_shape_ne_10_128.head()\n",
    "\n",
    "# Padding features_col_shape_ne_10_128 thành (10, 128)\n",
    "def padding_shape_1element_to_10_128(element): \n",
    "    current_shape = element.shape \n",
    "    paddding_shape = (10 - current_shape[0], 128)\n",
    "    new_element = np.r_[element, np.zeros(paddding_shape)]\n",
    "    return new_element\n",
    "\n",
    "features_col_shape_ne_10_128_padded = features_col_shape_ne_10_128.apply(padding_shape_1element_to_10_128)\n",
    "features_col_shape_ne_10_128_padded.iloc[0].shape\n",
    "\n",
    "# Thay thế các phần tử đã padding vào lại features_col\n",
    "features_col[features_col_shape_ne_10_128_padded.index] = features_col_shape_ne_10_128_padded\n",
    "\n",
    "set(features_col.apply(lambda x: x.shape))\n",
    "\n",
    "features_col_flattened = features_col.apply(lambda x: x.reshape(-1))\n",
    "features_col_flattened.head()\n",
    "\n",
    "df_features = pd.DataFrame(features_col_flattened.to_numpy().tolist())\n",
    "df_features.shape\n",
    "\n",
    "df_target = targets_col \n",
    "df_target.shape\n",
    "\n",
    "\n",
    "class DataCorrector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        df_train = X\n",
    "        feature_col = 'audio_embedding'\n",
    "        target_col = 'is_turkey'\n",
    "\n",
    "        features_col = df_train[feature_col]\n",
    "        targets_col = df_train[target_col]\n",
    "\n",
    "        features_col = features_col.apply(lambda x: np.asarray(x))\n",
    "        features_col_shape_ne_10_128 = features_col[features_col.apply(lambda x: x.shape != (10, 128))]\n",
    "        features_col_shape_ne_10_128_padded = features_col_shape_ne_10_128.apply(self.padding_shape_1element_to_10_128)\n",
    "        features_col[features_col_shape_ne_10_128_padded.index] = features_col_shape_ne_10_128_padded\n",
    "        features_col_flattened = features_col.apply(lambda x: x.reshape(-1))\n",
    "        df_features = pd.DataFrame(features_col_flattened.to_numpy().tolist())\n",
    "\n",
    "        df_target = targets_col \n",
    "\n",
    "        return df_features, df_target\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def padding_shape_1element_to_10_128(self, element): \n",
    "        current_shape = element.shape \n",
    "        paddding_shape = (10 - current_shape[0], 128)\n",
    "        new_element = np.r_[element, np.zeros(paddding_shape)]\n",
    "        return new_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47363581",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_models_desc = [\n",
    "    (1, SVC(kernel='linear', C=0.01, probability=True)),\n",
    "    (2, SVC(kernel='linear', C=0.1, probability=True)),\n",
    "    (3, SVC(kernel='linear', C=1, probability=True)),\n",
    "    (4, SVC(kernel='linear', C=10, probability=True)),\n",
    "    (5, SVC(kernel='linear', C=100, probability=True)),\n",
    "\n",
    "    (6, SVC(kernel='poly', degree=2, C=0.01, coef0 = 0.5,  probability=True)),\n",
    "    (7, SVC(kernel='poly',degree=2, C=0.1,coef0 = 0.5,  probability=True)),\n",
    "    (8, SVC(kernel='poly',degree=2, C=1,coef0 = 0.5,  probability=True)),\n",
    "    (9, SVC(kernel='poly',degree=2, C=10,coef0 = 0.5,  probability=True)),\n",
    "    (10, SVC(kernel='poly',degree=2, C=100,coef0 = 0.5,  probability=True)),\n",
    "\n",
    "    (11, SVC(kernel='poly', degree=2, C=0.01, coef0 = 0.3,  probability=True)),\n",
    "    (12, SVC(kernel='poly',degree=2, C=0.1,coef0 = 0.3,  probability=True)),\n",
    "    (13, SVC(kernel='poly',degree=2, C=1,coef0 = 0.3,  probability=True)),\n",
    "    (14, SVC(kernel='poly',degree=2, C=10,coef0 = 0.3,  probability=True)),\n",
    "    (15, SVC(kernel='poly',degree=2, C=100,coef0 = 0.3,  probability=True)),\n",
    "\n",
    "    (16, SVC(kernel='poly', degree=2, C=0.01, coef0 = 0.8,  probability=True)),\n",
    "    (17, SVC(kernel='poly',degree=2, C=0.1,coef0 = 0.8,  probability=True)),\n",
    "    (18, SVC(kernel='poly',degree=2, C=1,coef0 = 0.8,  probability=True)),\n",
    "    (19, SVC(kernel='poly',degree=2, C=10,coef0 = 0.8,  probability=True)),\n",
    "    (20, SVC(kernel='poly',degree=2, C=100,coef0 = 0.8,  probability=True)),\n",
    "\n",
    "    (21, SVC(kernel='poly', degree=2, C=0.01, coef0 = 0.1,  probability=True)),\n",
    "    (22, SVC(kernel='poly',degree=2, C=0.1,coef0 = 0.1,  probability=True)),\n",
    "    (23, SVC(kernel='poly',degree=2, C=1,coef0 = 0.1,  probability=True)),\n",
    "    (24, SVC(kernel='poly',degree=2, C=10,coef0 = 0.1,  probability=True)),\n",
    "    (25, SVC(kernel='poly',degree=2, C=100,coef0 = 0.1,  probability=True)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c38ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_models_desc = [\n",
    "    (1, DecisionTreeClassifier(max_depth = 10, max_leaf_nodes = 20)),\n",
    "    (2, DecisionTreeClassifier(max_depth = 20, max_leaf_nodes = 20)),\n",
    "    (3, DecisionTreeClassifier(max_depth = 30, max_leaf_nodes = 20)),\n",
    "    (4, DecisionTreeClassifier(max_depth = 40, max_leaf_nodes = 20)),\n",
    "    (5, DecisionTreeClassifier(max_depth = 50, max_leaf_nodes = 20)),\n",
    "\n",
    "    (6, DecisionTreeClassifier(max_depth = 10, max_leaf_nodes = 30)),\n",
    "    (7, DecisionTreeClassifier(max_depth = 20, max_leaf_nodes = 30)),\n",
    "    (8, DecisionTreeClassifier(max_depth = 30, max_leaf_nodes = 30)),\n",
    "    (9, DecisionTreeClassifier(max_depth = 40, max_leaf_nodes = 30)),\n",
    "    (10, DecisionTreeClassifier(max_depth = 50, max_leaf_nodes = 30)),\n",
    "\n",
    "    (11, DecisionTreeClassifier(max_depth = 10, max_leaf_nodes = 40)),\n",
    "    (12, DecisionTreeClassifier(max_depth = 20, max_leaf_nodes = 40)),\n",
    "    (13, DecisionTreeClassifier(max_depth = 30, max_leaf_nodes = 40)),\n",
    "    (14, DecisionTreeClassifier(max_depth = 40, max_leaf_nodes = 40)),\n",
    "    (15, DecisionTreeClassifier(max_depth = 50, max_leaf_nodes = 40)),\n",
    "\n",
    "    (16, DecisionTreeClassifier(max_depth = 10, max_leaf_nodes = 50)),\n",
    "    (17, DecisionTreeClassifier(max_depth = 20, max_leaf_nodes = 50)),\n",
    "    (18, DecisionTreeClassifier(max_depth = 30, max_leaf_nodes = 50)),\n",
    "    (19, DecisionTreeClassifier(max_depth = 40, max_leaf_nodes = 50)),\n",
    "    (20, DecisionTreeClassifier(max_depth = 50, max_leaf_nodes = 50)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a0ce598",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ComplexWarning' from 'numpy.core.numeric' (c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\numpy\\core\\numeric.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      3\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\sklearn\\__init__.py:83\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     80\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     )\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     86\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    130\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\sklearn\\utils\\__init__.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\sklearn\\utils\\validation.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# mypy error: Module 'numpy.core.numeric' has no attribute 'ComplexWarning'\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumeric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ComplexWarning  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ComplexWarning' from 'numpy.core.numeric' (c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\numpy\\core\\numeric.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, max_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9bf180",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_models_desc = [\n",
    "    (1, RandomForestClassifier(n_estimators=100, max_depth=10)),\n",
    "    (2, RandomForestClassifier(n_estimators=200, max_depth=10)),\n",
    "    (3, RandomForestClassifier(n_estimators=300, max_depth=10)),\n",
    "    (4, RandomForestClassifier(n_estimators=400, max_depth=10)),\n",
    "\n",
    "    (5, RandomForestClassifier(n_estimators=100, max_depth=20)),\n",
    "    (6, RandomForestClassifier(n_estimators=200, max_depth=20)),\n",
    "    (7, RandomForestClassifier(n_estimators=300, max_depth=20)),\n",
    "    (8, RandomForestClassifier(n_estimators=400, max_depth=20)),\n",
    "    \n",
    "    (9, RandomForestClassifier(n_estimators=100, max_depth=30)),\n",
    "    (10, RandomForestClassifier(n_estimators=200, max_depth=30)),\n",
    "    (11, RandomForestClassifier(n_estimators=300, max_depth=30)),\n",
    "    (12, RandomForestClassifier(n_estimators=400, max_depth=30)),\n",
    "\n",
    "    (13, RandomForestClassifier(n_estimators=100, max_depth=40)),\n",
    "    (14, RandomForestClassifier(n_estimators=200, max_depth=40)),\n",
    "    (15, RandomForestClassifier(n_estimators=300, max_depth=40)),\n",
    "    (16, RandomForestClassifier(n_estimators=400, max_depth=40)),\n",
    "\n",
    "    (17, RandomForestClassifier(n_estimators=100, max_depth=10, max_samples=0.9)),\n",
    "    (18, RandomForestClassifier(n_estimators=200, max_depth=10, max_samples=0.9)),\n",
    "    (19, RandomForestClassifier(n_estimators=300, max_depth=10, max_samples=0.9)),\n",
    "    (20, RandomForestClassifier(n_estimators=400, max_depth=10, max_samples=0.9)),\n",
    "\n",
    "    (21, RandomForestClassifier(n_estimators=100, max_depth=20, max_samples=0.9)),\n",
    "    (22, RandomForestClassifier(n_estimators=200, max_depth=20, max_samples=0.9)),\n",
    "    (23, RandomForestClassifier(n_estimators=300, max_depth=20, max_samples=0.9)),\n",
    "    (24, RandomForestClassifier(n_estimators=400, max_depth=20, max_samples=0.9)),\n",
    "    \n",
    "    (25, RandomForestClassifier(n_estimators=100, max_depth=30, max_samples=0.9)),\n",
    "    (26, RandomForestClassifier(n_estimators=200, max_depth=30, max_samples=0.9)),\n",
    "    (27, RandomForestClassifier(n_estimators=300, max_depth=30, max_samples=0.9)),\n",
    "    (28, RandomForestClassifier(n_estimators=400, max_depth=30, max_samples=0.9)),\n",
    "\n",
    "    (29, RandomForestClassifier(n_estimators=100, max_depth=40, max_samples=0.9)),\n",
    "    (30, RandomForestClassifier(n_estimators=200, max_depth=40, max_samples=0.9)),\n",
    "    (31, RandomForestClassifier(n_estimators=300, max_depth=40, max_samples=0.9)),\n",
    "    (32, RandomForestClassifier(n_estimators=400, max_depth=40, max_samples=0.9)),\n",
    "\n",
    "    (33, RandomForestClassifier(n_estimators=100, max_depth=10, max_samples=0.5)),\n",
    "    (34, RandomForestClassifier(n_estimators=200, max_depth=10, max_samples=0.5)),\n",
    "    (35, RandomForestClassifier(n_estimators=300, max_depth=10, max_samples=0.5)),\n",
    "    (36, RandomForestClassifier(n_estimators=400, max_depth=10, max_samples=0.5)),\n",
    "\n",
    "    (37, RandomForestClassifier(n_estimators=100, max_depth=20, max_samples=0.5)),\n",
    "    (38, RandomForestClassifier(n_estimators=200, max_depth=20, max_samples=0.5)),\n",
    "    (39, RandomForestClassifier(n_estimators=300, max_depth=20, max_samples=0.5)),\n",
    "    (40, RandomForestClassifier(n_estimators=400, max_depth=20, max_samples=0.5)),\n",
    "    \n",
    "    (41, RandomForestClassifier(n_estimators=100, max_depth=30, max_samples=0.5)),\n",
    "    (42, RandomForestClassifier(n_estimators=200, max_depth=30, max_samples=0.5)),\n",
    "    (43, RandomForestClassifier(n_estimators=300, max_depth=30, max_samples=0.5)),\n",
    "    (44, RandomForestClassifier(n_estimators=400, max_depth=30, max_samples=0.5)),\n",
    "\n",
    "    (45, RandomForestClassifier(n_estimators=100, max_depth=40, max_samples=0.5)),\n",
    "    (46, RandomForestClassifier(n_estimators=200, max_depth=40, max_samples=0.5)),\n",
    "    (47, RandomForestClassifier(n_estimators=300, max_depth=40, max_samples=0.5)),\n",
    "    (48, RandomForestClassifier(n_estimators=400, max_depth=40, max_samples=0.5)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d819883",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_models_desc = [\n",
    "    (1, XGBClassifier(n_estimators=100, max_depth=10, learning_rate=0.1)),\n",
    "    (2, XGBClassifier(n_estimators=200, max_depth=10, learning_rate=0.1)),\n",
    "    (3, XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.1)),\n",
    "    (4, XGBClassifier(n_estimators=400, max_depth=10, learning_rate=0.1)),\n",
    "\n",
    "    (5, XGBClassifier(n_estimators=100, max_depth=20, learning_rate=0.1)),\n",
    "    (6, XGBClassifier(n_estimators=200, max_depth=20, learning_rate=0.1)),\n",
    "    (7, XGBClassifier(n_estimators=300, max_depth=20, learning_rate=0.1)),\n",
    "    (8, XGBClassifier(n_estimators=400, max_depth=20, learning_rate=0.1)),\n",
    "\n",
    "    (9, XGBClassifier(n_estimators=100, max_depth=30, learning_rate=0.1)),\n",
    "    (10, XGBClassifier(n_estimators=200, max_depth=30, learning_rate=0.1)),\n",
    "    (11, XGBClassifier(n_estimators=300, max_depth=30, learning_rate=0.1)),\n",
    "    (12, XGBClassifier(n_estimators=400, max_depth=30, learning_rate=0.1)),\n",
    "\n",
    "    (13, XGBClassifier(n_estimators=100, max_depth=40, learning_rate=0.1)),\n",
    "    (14, XGBClassifier(n_estimators=200, max_depth=40, learning_rate=0.1)),\n",
    "    (15, XGBClassifier(n_estimators=300, max_depth=40, learning_rate=0.1)),\n",
    "    (16, XGBClassifier(n_estimators=400, max_depth=40, learning_rate=0.1)),\n",
    "\n",
    "    (17, XGBClassifier(n_estimators=100, max_depth=10, learning_rate=0.01)),\n",
    "    (18, XGBClassifier(n_estimators=200, max_depth=10, learning_rate=0.01)),\n",
    "    (19, XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.01)),\n",
    "    (20, XGBClassifier(n_estimators=400, max_depth=10, learning_rate=0.01)),\n",
    "\n",
    "    (21, XGBClassifier(n_estimators=100, max_depth=20, learning_rate=0.01)),\n",
    "    (22, XGBClassifier(n_estimators=200, max_depth=20, learning_rate=0.01)),\n",
    "    (23, XGBClassifier(n_estimators=300, max_depth=20, learning_rate=0.01)),\n",
    "    (24, XGBClassifier(n_estimators=400, max_depth=20, learning_rate=0.01)),\n",
    "\n",
    "    (25, XGBClassifier(n_estimators=100, max_depth=30, learning_rate=0.01)),\n",
    "    (26, XGBClassifier(n_estimators=200, max_depth=30, learning_rate=0.01)),\n",
    "    (27, XGBClassifier(n_estimators=300, max_depth=30, learning_rate=0.01)),\n",
    "    (28, XGBClassifier(n_estimators=400, max_depth=30, learning_rate=0.01)),\n",
    "\n",
    "    (29, XGBClassifier(n_estimators=100, max_depth=40, learning_rate=0.01)),\n",
    "    (30, XGBClassifier(n_estimators=200, max_depth=40, learning_rate=0.01)),\n",
    "    (31, XGBClassifier(n_estimators=300, max_depth=40, learning_rate=0.01)),\n",
    "    (32, XGBClassifier(n_estimators=400, max_depth=40, learning_rate=0.01)),\n",
    "\n",
    "    ###\n",
    "    (33, XGBClassifier(n_estimators=100, max_depth=10, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "    (34, XGBClassifier(n_estimators=200, max_depth=10, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "    (35, XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "    (36, XGBClassifier(n_estimators=400, max_depth=10, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "\n",
    "    (37, XGBClassifier(n_estimators=100, max_depth=20, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "    (38, XGBClassifier(n_estimators=200, max_depth=20, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "    (39, XGBClassifier(n_estimators=300, max_depth=20, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "    (40, XGBClassifier(n_estimators=400, max_depth=20, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "\n",
    "    (41, XGBClassifier(n_estimators=100, max_depth=30, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "    (42, XGBClassifier(n_estimators=200, max_depth=30, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "    (43, XGBClassifier(n_estimators=300, max_depth=30, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "    (44, XGBClassifier(n_estimators=400, max_depth=30, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "\n",
    "    (45, XGBClassifier(n_estimators=100, max_depth=40, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "    (46, XGBClassifier(n_estimators=200, max_depth=40, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "    (47, XGBClassifier(n_estimators=300, max_depth=40, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "    (48, XGBClassifier(n_estimators=400, max_depth=40, learning_rate=0.1, reg_alpha=1, reg_lambda=1)),\n",
    "\n",
    "    ### \n",
    "    (49, XGBClassifier(n_estimators=100, max_depth=10, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "    (50, XGBClassifier(n_estimators=200, max_depth=10, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "    (51, XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "    (52, XGBClassifier(n_estimators=400, max_depth=10, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "\n",
    "    (53, XGBClassifier(n_estimators=100, max_depth=20, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "    (54, XGBClassifier(n_estimators=200, max_depth=20, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "    (55, XGBClassifier(n_estimators=300, max_depth=20, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "    (56, XGBClassifier(n_estimators=400, max_depth=20, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "\n",
    "    (57, XGBClassifier(n_estimators=100, max_depth=30, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "    (58, XGBClassifier(n_estimators=200, max_depth=30, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "    (59, XGBClassifier(n_estimators=300, max_depth=30, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "    (60, XGBClassifier(n_estimators=400, max_depth=30, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "\n",
    "    (61, XGBClassifier(n_estimators=100, max_depth=40, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "    (62, XGBClassifier(n_estimators=200, max_depth=40, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "    (63, XGBClassifier(n_estimators=300, max_depth=40, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "    (64, XGBClassifier(n_estimators=400, max_depth=40, learning_rate=0.1, reg_alpha=5, reg_lambda=1)),\n",
    "\n",
    "    ### \n",
    "    (65, XGBClassifier(n_estimators=100, max_depth=10, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "    (66, XGBClassifier(n_estimators=200, max_depth=10, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "    (67, XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "    (68, XGBClassifier(n_estimators=400, max_depth=10, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "\n",
    "    (69, XGBClassifier(n_estimators=100, max_depth=20, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "    (70, XGBClassifier(n_estimators=200, max_depth=20, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "    (71, XGBClassifier(n_estimators=300, max_depth=20, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "    (72, XGBClassifier(n_estimators=400, max_depth=20, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "\n",
    "    (73, XGBClassifier(n_estimators=100, max_depth=30, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "    (74, XGBClassifier(n_estimators=200, max_depth=30, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "    (75, XGBClassifier(n_estimators=300, max_depth=30, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "    (76, XGBClassifier(n_estimators=400, max_depth=30, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "\n",
    "    (77, XGBClassifier(n_estimators=100, max_depth=40, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "    (78, XGBClassifier(n_estimators=200, max_depth=40, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "    (79, XGBClassifier(n_estimators=300, max_depth=40, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "    (80, XGBClassifier(n_estimators=400, max_depth=40, learning_rate=0.1, reg_alpha=5, reg_lambda=5)),\n",
    "\n",
    "    #######\n",
    "    (81, XGBClassifier(n_estimators=100, max_depth=10, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "    (82, XGBClassifier(n_estimators=200, max_depth=10, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "    (83, XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "    (84, XGBClassifier(n_estimators=400, max_depth=10, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "\n",
    "    (85, XGBClassifier(n_estimators=100, max_depth=20, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "    (86, XGBClassifier(n_estimators=200, max_depth=20, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "    (87, XGBClassifier(n_estimators=300, max_depth=20, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "    (88, XGBClassifier(n_estimators=400, max_depth=20, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "\n",
    "    (89, XGBClassifier(n_estimators=100, max_depth=30, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "    (90, XGBClassifier(n_estimators=200, max_depth=30, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "    (91, XGBClassifier(n_estimators=300, max_depth=30, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "    (92, XGBClassifier(n_estimators=400, max_depth=30, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "\n",
    "    (93, XGBClassifier(n_estimators=100, max_depth=40, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "    (94, XGBClassifier(n_estimators=200, max_depth=40, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "    (95, XGBClassifier(n_estimators=300, max_depth=40, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "    (96, XGBClassifier(n_estimators=400, max_depth=40, learning_rate=0.01, reg_alpha=1, reg_lambda=1)),\n",
    "\n",
    "    ### \n",
    "    (97, XGBClassifier(n_estimators=100, max_depth=10, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "    (98, XGBClassifier(n_estimators=200, max_depth=10, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "    (99, XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "    (100, XGBClassifier(n_estimators=400, max_depth=10, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "\n",
    "    (101, XGBClassifier(n_estimators=100, max_depth=20, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "    (102, XGBClassifier(n_estimators=200, max_depth=20, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "    (103, XGBClassifier(n_estimators=300, max_depth=20, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "    (104, XGBClassifier(n_estimators=400, max_depth=20, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "\n",
    "    (105, XGBClassifier(n_estimators=100, max_depth=30, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "    (106, XGBClassifier(n_estimators=200, max_depth=30, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "    (107, XGBClassifier(n_estimators=300, max_depth=30, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "    (108, XGBClassifier(n_estimators=400, max_depth=30, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "\n",
    "    (109, XGBClassifier(n_estimators=100, max_depth=40, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "    (110, XGBClassifier(n_estimators=200, max_depth=40, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "    (111, XGBClassifier(n_estimators=300, max_depth=40, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "    (112, XGBClassifier(n_estimators=400, max_depth=40, learning_rate=0.01, reg_alpha=5, reg_lambda=1)),\n",
    "\n",
    "    ### \n",
    "    (113, XGBClassifier(n_estimators=100, max_depth=10, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "    (114, XGBClassifier(n_estimators=200, max_depth=10, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "    (115, XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "    (116, XGBClassifier(n_estimators=400, max_depth=10, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "\n",
    "    (117, XGBClassifier(n_estimators=100, max_depth=20, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "    (118, XGBClassifier(n_estimators=200, max_depth=20, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "    (119, XGBClassifier(n_estimators=300, max_depth=20, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "    (120, XGBClassifier(n_estimators=400, max_depth=20, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "\n",
    "    (121, XGBClassifier(n_estimators=100, max_depth=30, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "    (122, XGBClassifier(n_estimators=200, max_depth=30, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "    (123, XGBClassifier(n_estimators=300, max_depth=30, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "    (124, XGBClassifier(n_estimators=400, max_depth=30, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "\n",
    "    (125, XGBClassifier(n_estimators=100, max_depth=40, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "    (126, XGBClassifier(n_estimators=200, max_depth=40, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "    (127, XGBClassifier(n_estimators=300, max_depth=40, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "    (128, XGBClassifier(n_estimators=400, max_depth=40, learning_rate=0.01, reg_alpha=5, reg_lambda=5)),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3bb1930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1   2024-11-20\n",
       "2   2024-05-20\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dates = [\n",
    "    \"20/11/2024.log\",\n",
    "    \"20/5/2024.log\",\n",
    "    \"20/12/2024.log\",\n",
    "    \"20/4/2024.log\",\n",
    "]\n",
    "\n",
    "from datetime import datetime \n",
    "import pandas as pd\n",
    "\n",
    "date_format = \"%d/%m/%Y.log\"\n",
    "list_dates = [datetime.strptime(item, date_format) for item in list_dates]\n",
    "sorted_list_dates = sorted(list_dates, reverse=True)\n",
    "\n",
    "a = pd.Series(sorted_list_dates)\n",
    "b = datetime.strptime(\"19/5/2024.log\",  date_format)\n",
    "c = datetime.strptime(\"19/12/2024.log\",  date_format)\n",
    "\n",
    "a = a[(a>b) & (a<c)]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a49dc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 2, 3, 4, 4, 5, 6]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1,2], [2,3,4], [4,5,6]]\n",
    "\n",
    "import itertools\n",
    "\n",
    "b = list(itertools.chain(*a))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    (255, LGBMClassifier(n_estimators = 10, max_depth = 1, learning_rate = 1)), \n",
    "    (256, LGBMClassifier(n_estimators = 10, max_depth = 2, learning_rate = 1)), \n",
    "    (257, LGBMClassifier(n_estimators = 10, max_depth = 3, learning_rate = 1)), \n",
    "    (258, LGBMClassifier(n_estimators = 10, max_depth = 4, learning_rate = 1)), \n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1c183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    (259, LGBMClassifier(n_estimators = 500, max_depth = 50, learning_rate = 0.001)), \n",
    "    (260, LGBMClassifier(n_estimators = 500, max_depth = 60, learning_rate = 0.001)), \n",
    "    (261, LGBMClassifier(n_estimators = 600, max_depth = 60, learning_rate = 0.001)), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f08d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_21960\\823288527.py\", line 1, in <module>\n",
      "    from Mylib import tf_myfuncs\n",
      "  File \"d:\\DA_workspace\\Template_ML_projects_to_run_on_colab\\Mylib\\Mylib\\tf_myfuncs.py\", line 1, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.eager import context\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 35, in <module>\n",
      "    from tensorflow.python.client import pywrap_tf_session\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\client\\pywrap_tf_session.py\", line 19, in <module>\n",
      "    from tensorflow.python.client._pywrap_tf_session import *\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_21960\\823288527.py\", line 1, in <module>\n",
      "    from Mylib import tf_myfuncs\n",
      "  File \"d:\\DA_workspace\\Template_ML_projects_to_run_on_colab\\Mylib\\Mylib\\tf_myfuncs.py\", line 1, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 42, in <module>\n",
      "    from tensorflow.python import data\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py\", line 21, in <module>\n",
      "    from tensorflow.python.data import experimental\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\", line 96, in <module>\n",
      "    from tensorflow.python.data.experimental import service\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\", line 419, in <module>\n",
      "    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\", line 24, in <module>\n",
      "    from tensorflow.python.data.experimental.ops import compression_ops\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py\", line 16, in <module>\n",
      "    from tensorflow.python.data.util import structure\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\", line 23, in <module>\n",
      "    from tensorflow.python.data.util import nest\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\", line 36, in <module>\n",
      "    from tensorflow.python.framework import sparse_tensor as _sparse_tensor\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\", line 24, in <module>\n",
      "    from tensorflow.python.framework import constant_op\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 25, in <module>\n",
      "    from tensorflow.python.eager import execute\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 23, in <module>\n",
      "    from tensorflow.python.framework import dtypes\n",
      "  File \"c:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py\", line 29, in <module>\n",
      "    from tensorflow.python.lib.core import _pywrap_bfloat16\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to convert function return value to a Python type! The signature was\n\t() -> handle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMylib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_myfuncs\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping \n\u001b[0;32m      4\u001b[0m a \u001b[38;5;241m=\u001b[39m EarlyStopping()\n",
      "File \u001b[1;32md:\\DA_workspace\\Template_ML_projects_to_run_on_colab\\Mylib\\Mylib\\tf_myfuncs.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metrics\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\__init__.py:42\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:96\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:419\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structure\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompress\u001b[39m(element):\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwrapt\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py:36\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"## Functions for working with arbitrarily nested sequences of elements.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03mNOTE(mrry): This fork of the `tensorflow.python.util.nest` module\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m   arrays.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_six\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m _sparse_tensor\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nest\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constant_op\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types_pb2\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m execute\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m op_callbacks\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:34\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trace\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trace_type\n\u001b[1;32m---> 34\u001b[0m _np_bfloat16 \u001b[38;5;241m=\u001b[39m \u001b[43m_pywrap_bfloat16\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_bfloat16_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mDTypeMeta\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(_dtypes\u001b[38;5;241m.\u001b[39mDType), abc\u001b[38;5;241m.\u001b[39mABCMeta):\n\u001b[0;32m     38\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to convert function return value to a Python type! The signature was\n\t() -> handle"
     ]
    }
   ],
   "source": [
    "from Mylib import tf_myfuncs\n",
    "from tf.keras.callbacks import EarlyStopping \n",
    "\n",
    "a = EarlyStopping()\n",
    "\n",
    "b = tf_myfuncs.copy_one_callback(a)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c5ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [[Logic, XGB, RandomForest], [Logic, XGB]]\n",
    "final_estimator = RandomForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e9604d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(models[0].weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "493365f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 3, 4],\n",
       "       [2, 3, 4, 5, 4, 5]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "a = np.asarray([[1,2], [2,3]])\n",
    "b = np.asarray([[3,4], [4,5]])\n",
    "c = np.asarray([[3,4], [4,5]])\n",
    "\n",
    "c = [a,b, c]\n",
    "\n",
    "np.hstack(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ebb6fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj =  ast.literal_eval(\"[1,2]\")\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dd9e278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = os.path.join(\"artifacts\", \"hello.pkl\")\n",
    "filename = os.path.splitext(os.path.basename(path))[0]\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1582678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yaml file: demo.yaml loaded successfully\n",
      "class_name: CustomStackingClassifier\n",
      "estimators:\n",
      "   - LogisticRegression(C = 0.1)\n",
      "   - GaussianNB(var_smoothing=1e-8)\n",
      "   - SGDClassifier(alpha=10, loss='log_loss')\n",
      "final_estimator: LogisticRegression(C = 0.1)\n"
     ]
    }
   ],
   "source": [
    "from Mylib import stringToObjectConverter, myfuncs\n",
    "\n",
    "\n",
    "models = myfuncs.read_yaml(\"demo.yaml\").models\n",
    "\n",
    "model = models[0]\n",
    "\n",
    "print(myfuncs.get_model_desc_for_CustomStackingClassifier(model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c77a284",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'hello'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m         model\u001b[38;5;241m.\u001b[39mfit(X_batch, y_batch)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;66;03m# Tiếp tục huấn luyện từ mô hình đã huấn luyện trước đó\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhello\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Dự đoán và đánh giá mô hình\u001b[39;00m\n\u001b[0;32m     34\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'hello'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "\n",
    "# Giả sử bạn có một tập dữ liệu với 10,000 dòng\n",
    "X, y = make_classification(n_samples=10000, n_features=20, random_state=42)\n",
    "\n",
    "# Khởi tạo XGBClassifier\n",
    "model = XGBClassifier(n_estimators=5, learning_rate=0.1)\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "list_X_batch = [\n",
    "    X[i : i + batch_size, :]\n",
    "    for i in range(0, len(X), batch_size)\n",
    "]\n",
    "\n",
    "list_y_batch = [\n",
    "    y[i : i + batch_size]\n",
    "    for i in range(0, len(X), batch_size)\n",
    "]\n",
    "\n",
    "# Lặp qua từng batch, huấn luyện mô hình\n",
    "for i, (X_batch, y_batch) in enumerate(zip(list_X_batch, list_y_batch)):\n",
    "    if i == 0:\n",
    "        # Huấn luyện lần đầu tiên\n",
    "        model.fit(X_batch, y_batch)\n",
    "    else:\n",
    "        # Tiếp tục huấn luyện từ mô hình đã huấn luyện trước đó\n",
    "        model.fit(X_batch, y_batch, xgb_model=model.get_booster())\n",
    "\n",
    "# Dự đoán và đánh giá mô hình\n",
    "y_pred = model.predict(X)\n",
    "accuracy = metrics.accuracy_score(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59b47981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "\n",
    "isinstance(model, XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1e98d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['warm_start   = True',\n",
       " 'hidden_layer_sizes=(64,32,16),',\n",
       " \"activation='relu',\",\n",
       " 'max_iter=100,',\n",
       " 'batch_size=1024,',\n",
       " 'validation_fraction=0',\n",
       " 'early_stopping=True)']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"MLPClassifier(   warm_start   = True   ,hidden_layer_sizes=(64,32,16), activation='relu', max_iter=100, batch_size=1024, validation_fraction=0.1, early_stopping=True)\"\n",
    "\n",
    "# Tách tên lớp và tham số\n",
    "class_name = text.split(\"(\", 1)[0]\n",
    "\n",
    "object_class = globals()[class_name]\n",
    "\n",
    "format = r\"\\w+\\s*=\\s*[\\w\\(\\),\\']+\"\n",
    "param = re.findall(format, text)\n",
    "\n",
    "param\n",
    "\n",
    "# param_name = [item.split(\"=\")[0].strip() for item in param]\n",
    "# param_value = [item.split(\"=\")[1].strip() for item in param]\n",
    "\n",
    "# param_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee5241d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05de3a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.4\n"
     ]
    }
   ],
   "source": [
    "import xgboost \n",
    "\n",
    "print(xgboost.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c58c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.097248</td>\n",
       "      <td>-0.043218</td>\n",
       "      <td>-0.265815</td>\n",
       "      <td>0.111935</td>\n",
       "      <td>0.150092</td>\n",
       "      <td>-0.016558</td>\n",
       "      <td>0.017185</td>\n",
       "      <td>0.103372</td>\n",
       "      <td>0.049894</td>\n",
       "      <td>-0.184696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.186874</td>\n",
       "      <td>-0.134880</td>\n",
       "      <td>-0.117323</td>\n",
       "      <td>-0.049524</td>\n",
       "      <td>0.111066</td>\n",
       "      <td>-0.218406</td>\n",
       "      <td>0.167135</td>\n",
       "      <td>-0.051754</td>\n",
       "      <td>-0.007685</td>\n",
       "      <td>-0.035729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.155977</td>\n",
       "      <td>-0.006309</td>\n",
       "      <td>-0.017333</td>\n",
       "      <td>0.201616</td>\n",
       "      <td>0.098383</td>\n",
       "      <td>0.190598</td>\n",
       "      <td>0.078926</td>\n",
       "      <td>-0.165511</td>\n",
       "      <td>-0.166385</td>\n",
       "      <td>0.136122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.312429</td>\n",
       "      <td>-0.111052</td>\n",
       "      <td>-0.050050</td>\n",
       "      <td>0.080957</td>\n",
       "      <td>0.201140</td>\n",
       "      <td>0.092766</td>\n",
       "      <td>-0.114738</td>\n",
       "      <td>-0.086712</td>\n",
       "      <td>0.042215</td>\n",
       "      <td>-0.099011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.031333</td>\n",
       "      <td>0.097333</td>\n",
       "      <td>-0.057367</td>\n",
       "      <td>-0.030342</td>\n",
       "      <td>0.154183</td>\n",
       "      <td>-0.073601</td>\n",
       "      <td>-0.153181</td>\n",
       "      <td>-0.064510</td>\n",
       "      <td>0.062237</td>\n",
       "      <td>0.016441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.395789</td>\n",
       "      <td>-0.092389</td>\n",
       "      <td>-0.003644</td>\n",
       "      <td>0.152082</td>\n",
       "      <td>-0.080188</td>\n",
       "      <td>0.011601</td>\n",
       "      <td>-0.082576</td>\n",
       "      <td>-0.090687</td>\n",
       "      <td>-0.218288</td>\n",
       "      <td>-0.054186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.204065</td>\n",
       "      <td>-0.246415</td>\n",
       "      <td>0.214963</td>\n",
       "      <td>0.215878</td>\n",
       "      <td>0.085831</td>\n",
       "      <td>0.234779</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>0.079624</td>\n",
       "      <td>0.099719</td>\n",
       "      <td>-0.057190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>-0.370814</td>\n",
       "      <td>-0.001821</td>\n",
       "      <td>-0.037114</td>\n",
       "      <td>0.213185</td>\n",
       "      <td>-0.205793</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.150469</td>\n",
       "      <td>0.023313</td>\n",
       "      <td>0.060360</td>\n",
       "      <td>0.276384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.237864</td>\n",
       "      <td>-0.085875</td>\n",
       "      <td>-0.226185</td>\n",
       "      <td>0.087428</td>\n",
       "      <td>-0.042542</td>\n",
       "      <td>-0.010563</td>\n",
       "      <td>-0.006005</td>\n",
       "      <td>-0.053812</td>\n",
       "      <td>0.141612</td>\n",
       "      <td>-0.199983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.129645</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>-0.030473</td>\n",
       "      <td>-0.182321</td>\n",
       "      <td>0.194892</td>\n",
       "      <td>0.094931</td>\n",
       "      <td>0.221302</td>\n",
       "      <td>0.173041</td>\n",
       "      <td>-0.129665</td>\n",
       "      <td>0.212641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.097248 -0.043218 -0.265815  0.111935  0.150092 -0.016558  0.017185   \n",
       "1     0.186874 -0.134880 -0.117323 -0.049524  0.111066 -0.218406  0.167135   \n",
       "2     0.155977 -0.006309 -0.017333  0.201616  0.098383  0.190598  0.078926   \n",
       "3    -0.312429 -0.111052 -0.050050  0.080957  0.201140  0.092766 -0.114738   \n",
       "4     0.031333  0.097333 -0.057367 -0.030342  0.154183 -0.073601 -0.153181   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  0.395789 -0.092389 -0.003644  0.152082 -0.080188  0.011601 -0.082576   \n",
       "9996  0.204065 -0.246415  0.214963  0.215878  0.085831  0.234779  0.058144   \n",
       "9997 -0.370814 -0.001821 -0.037114  0.213185 -0.205793  0.033708  0.150469   \n",
       "9998  0.237864 -0.085875 -0.226185  0.087428 -0.042542 -0.010563 -0.006005   \n",
       "9999  0.129645  0.234303 -0.030473 -0.182321  0.194892  0.094931  0.221302   \n",
       "\n",
       "             7         8         9  \n",
       "0     0.103372  0.049894 -0.184696  \n",
       "1    -0.051754 -0.007685 -0.035729  \n",
       "2    -0.165511 -0.166385  0.136122  \n",
       "3    -0.086712  0.042215 -0.099011  \n",
       "4    -0.064510  0.062237  0.016441  \n",
       "...        ...       ...       ...  \n",
       "9995 -0.090687 -0.218288 -0.054186  \n",
       "9996  0.079624  0.099719 -0.057190  \n",
       "9997  0.023313  0.060360  0.276384  \n",
       "9998 -0.053812  0.141612 -0.199983  \n",
       "9999  0.173041 -0.129665  0.212641  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 500\n",
    "list_X_batch = [\n",
    "X[i : i + batch_size, :]\n",
    "for i in range(0, len(X), batch_size)\n",
    "]\n",
    "\n",
    "list_y_batch = [\n",
    "y[i : i + batch_size]\n",
    "for i in range(0, len(X), batch_size)\n",
    "]\n",
    "\n",
    "for X_batch, y_batch in zip(list_X_batch, list_y_batch) : \n",
    "    model.fit(X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80a8e860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dfe05b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit batch no. 0\n",
      "Fit batch no. 1\n",
      "Fit batch no. 2\n",
      "Fit batch no. 3\n",
      "Fit batch no. 4\n",
      "Fit batch no. 5\n",
      "Fit batch no. 6\n",
      "Fit batch no. 7\n",
      "Fit batch no. 8\n",
      "Fit batch no. 9\n",
      "Fit batch no. 10\n",
      "Fit batch no. 11\n",
      "Fit batch no. 12\n",
      "Fit batch no. 13\n",
      "Fit batch no. 14\n",
      "Fit batch no. 15\n",
      "Fit batch no. 16\n",
      "Fit batch no. 17\n",
      "Fit batch no. 18\n",
      "Fit batch no. 19\n",
      "Tiến hành transform dữ liệu\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Chia dữ liệu thành 6 batch, mỗi batch có 50,000 dòng\n",
    "batch_size = 500\n",
    "num_batches = X.shape[0] // batch_size\n",
    "\n",
    "# Khởi tạo KernelPCA với kernel là 'rbf' (Radial Basis Function)\n",
    "kpca = KernelPCA(kernel='rbf', n_components=10)\n",
    "\n",
    "# Tính toán ma trận hạt nhân cho toàn bộ dữ liệu sau khi fit trên các batch\n",
    "# Không thực hiện transform ở đây, chỉ lưu các thông tin cần thiết\n",
    "for i in range(num_batches):\n",
    "    print(f\"Fit batch no. {i}\")\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch = X[start:end]\n",
    "\n",
    "    # Fit KernelPCA cho batch hiện tại\n",
    "    kpca.fit(batch)\n",
    "    \n",
    "# Sau khi fit tất cả các batch, transform toàn bộ dữ liệu\n",
    "print(\"Tiến hành transform dữ liệu\")\n",
    "X_transformed = kpca.transform(X)\n",
    "\n",
    "# Bây giờ, bạn có thể sử dụng X_transformed cho các tác vụ khác như phân loại, phân cụm,...\n",
    "print(X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "323c80c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06832064,  0.1522096 ],\n",
       "       [ 0.18322921,  0.02435615],\n",
       "       [ 0.03261752,  0.05863166],\n",
       "       ...,\n",
       "       [ 0.15806078,  0.23795613],\n",
       "       [-0.33751886,  0.00462025],\n",
       "       [-0.42269551, -0.19284862]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a7429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_ast_literal_eval_advanced_7(text: str):\n",
    "    \"\"\"Kế thừa hàm ast.literal_eval() nhưng xử lí thêm trường hợp sau\n",
    "\n",
    "    Tuple, List dạng (1.0 ; 2.0), các phần tử cách nhau bởi dấu ; thay vì dấu ,\n",
    "\n",
    "    \"\"\"\n",
    "    if \";\" not in text:\n",
    "        return ast.literal_eval(text)\n",
    "\n",
    "    return ast.literal_eval(text.replace(\";\", \",\"))\n",
    "\n",
    "\n",
    "def convert_complex_string_to_object_4(text: str):\n",
    "    \"\"\"Chuyển 1 chuỗi thành 1 đối tượng\n",
    "\n",
    "    Example:\n",
    "        text = \"LogisticRegression(C=144, penalty=l1, solver=saga ,max_iter=10000,dual=True)\"\n",
    "\n",
    "        -> đối tượng LogisticRegression(C=144, dual=True, max_iter=10000, penalty='l1',solver='saga')\n",
    "\n",
    "    Args:\n",
    "        text (str): _description_\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # Tách tên lớp và tham số\n",
    "    class_name, params = text.split(\"(\", 1)\n",
    "    params = params[:-1]\n",
    "\n",
    "    object_class = globals()[class_name]\n",
    "\n",
    "    if params == \"\":\n",
    "        return object_class()\n",
    "\n",
    "    # Lấy tham số của đối tượng\n",
    "    param_parts = params.split(\",\")\n",
    "    param_parts = [item.strip() for item in param_parts]\n",
    "    keys = [item.split(\"=\")[0].strip() for item in param_parts]\n",
    "\n",
    "    values = [\n",
    "        do_ast_literal_eval_advanced_7(item.strip().split(\"=\")[1].strip())\n",
    "        for item in param_parts\n",
    "    ]\n",
    "\n",
    "    params = dict(zip(keys, values))\n",
    "\n",
    "    return object_class(**params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72faec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    \"patience\": [5, 10], \n",
    "    \"min_delta\": [0.001], \n",
    "    \"epochs\": [30, 50], \n",
    "    \"learning_rate\": [0.001, 0.01], \n",
    "    \"layers\": [\n",
    "        {\n",
    "            \"name\": 'ImageDataPositionAugmentation', \n",
    "            \"rotation_factor\": 0.2,\n",
    "            \"zoom_factor\": 0.2, \n",
    "        }, \n",
    "        {\n",
    "            \"name\": 'Conv2DBlock_2Conv2DList', \n",
    "            \"start_filters\": 32, \n",
    "            \"num_layers\": [1,2,3,4,5], \n",
    "        }, \n",
    "        {\n",
    "            \"name\": ['Flatten', 'GlobalAveragePooling2D'], \n",
    "        }, \n",
    "        {\n",
    "            \"name\": 'DenseBatchNormalizationDropoutTuner',\n",
    "            \"dropout_rate\": 0.5,\n",
    "            \"start_units\": 32, \n",
    "            \"num_layers\": [1,2,3,4,5], \n",
    "        }, \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1989d010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param = {\n",
    "    # 'n_estimators': 100, \n",
    "    # 'max_depth': 50\n",
    "}\n",
    "\n",
    "a = RandomForestClassifier(**param)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "169cd0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "a = pd.Series([1,2,3])\n",
    "\n",
    "for item in a: \n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa6dffa8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Computed output size would be negative. Received `inputs shape=(None, 1, 1, 64)`, `kernel shape=(3, 3, 64, 128)`, `dilation_rate=[1 1]`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m3\u001b[39m)(x)\n\u001b[0;32m      9\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mMaxPooling2D(\u001b[38;5;241m2\u001b[39m)(x)\n\u001b[1;32m---> 10\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mMaxPooling2D(\u001b[38;5;241m2\u001b[39m)(x)\n\u001b[0;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m3\u001b[39m)(x)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv_new\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\ml_venv_new\\lib\\site-packages\\keras\\src\\ops\\operation_utils.py:221\u001b[0m, in \u001b[0;36mcompute_conv_output_shape\u001b[1;34m(input_shape, filters, kernel_size, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output_spatial_shape)):\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m none_dims \u001b[38;5;129;01mand\u001b[39;00m output_spatial_shape[i] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    222\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputed output size would be negative. Received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`inputs shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`kernel shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`dilation_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdilation_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    226\u001b[0m             )\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m padding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m padding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcausal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    228\u001b[0m     output_spatial_shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor((spatial_shape \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m strides) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Computed output size would be negative. Received `inputs shape=(None, 1, 1, 64)`, `kernel shape=(3, 3, 64, 128)`, `dilation_rate=[1 1]`."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "input = tf.keras.Input(shape = (12, 12, 3))\n",
    "x = layers.Conv2D(32, 3)(input)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(64, 3)(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3)(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(256, 3)(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(512, 3)(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(1024, 3)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "model =tf.keras.models.Model(input, x)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73c05583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "{'lr': 0.001, 'batch_size': 16}\n",
      "{'lr': 0.01, 'batch_size': 16}\n",
      "{'lr': 0.001, 'batch_size': 98}\n",
      "{'lr': 0.01, 'batch_size': 56}\n",
      "{'lr': 0.01, 'batch_size': 32}\n",
      "{'lr': 0.01, 'batch_size': 89}\n",
      "{'lr': 0.001, 'batch_size': 12}\n",
      "{'lr': 0.01, 'batch_size': 12}\n",
      "{'lr': 0.01, 'batch_size': 67}\n",
      "{'lr': 0.001, 'batch_size': 32}\n",
      "Full luon\n",
      "{'batch_size': 16, 'lr': 0.001}\n",
      "{'batch_size': 16, 'lr': 0.01}\n",
      "{'batch_size': 32, 'lr': 0.001}\n",
      "{'batch_size': 32, 'lr': 0.01}\n",
      "{'batch_size': 56, 'lr': 0.001}\n",
      "{'batch_size': 56, 'lr': 0.01}\n",
      "{'batch_size': 78, 'lr': 0.001}\n",
      "{'batch_size': 78, 'lr': 0.01}\n",
      "{'batch_size': 98, 'lr': 0.001}\n",
      "{'batch_size': 98, 'lr': 0.01}\n",
      "{'batch_size': 67, 'lr': 0.001}\n",
      "{'batch_size': 67, 'lr': 0.01}\n",
      "{'batch_size': 89, 'lr': 0.001}\n",
      "{'batch_size': 89, 'lr': 0.01}\n",
      "{'batch_size': 12, 'lr': 0.001}\n",
      "{'batch_size': 12, 'lr': 0.01}\n",
      "{'batch_size': 12, 'lr': 0.001}\n",
      "{'batch_size': 12, 'lr': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterSampler, ParameterGrid\n",
    "\n",
    "param_dict = {\n",
    "    \"lr\": [0.001, 0.01],\n",
    "    \"batch_size\": [16, 32, 56, 78, 98, 67, 89, 12,12],\n",
    "}\n",
    "\n",
    "total_combinations = 1\n",
    "for v in param_dict.values():\n",
    "    total_combinations *= len(v)\n",
    "\n",
    "print(total_combinations)\n",
    "\n",
    "# Only 4 combinations possible\n",
    "for x in ParameterSampler(param_dict, n_iter=10, random_state=42):\n",
    "    print(x)\n",
    "\n",
    "print(\"Full luon\")\n",
    "for y in ParameterGrid(param_dict): \n",
    "    print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512763fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
    "\n",
    "# First decoder GRU takes initial state\n",
    "x = layers.GRU(latent_dim, return_sequences=True)(x, initial_state=encoded_source)\n",
    "\n",
    "x = layers.GRU(latent_dim / 2, return_sequences=True)(x, initial_state=encoded_source)\n",
    "\n",
    "# Second decoder GRU layer (no initial_state)\n",
    "x = layers.GRU(latent_dim / 4, return_sequences=True)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bed0930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "\n",
    "a.remove(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b539c47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 1, 4, 3, 4, 4]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "a = [1, 2, 3, 4, 4, 4, 4, 4 ,4]\n",
    "random_three = random.sample(a, 6)\n",
    "random_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21118056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10000, penalty=&#x27;l1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>LogisticRegression(C=10000, penalty=&#x27;l1&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10000, penalty='l1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "layer_name = 'LogisticRegression'\n",
    "LayerName = globals()[layer_name]\n",
    "a = LayerName(C= 10000, penalty = 'l1')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d145e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "a = pd.Series(['run0', 'run1', 'run2'])\n",
    "\n",
    "b = a.str.extract(r'(\\d+)').astype('int')[0].tolist()\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e720a21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': (4,), 'b': (4, 4)}, {'a': (3, 3), 'b': (3, 3)}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trừ 2 danh sách, các phần tử trong danh sách là các set\n",
    "def subtract_2list_set(A, a):\n",
    "    set_A = set(tuple(sorted(d.items())) for d in A)\n",
    "    set_a = set(tuple(sorted(d.items())) for d in a)\n",
    "    diff = set_A - set_a\n",
    "    diff = [dict(t) for t in diff]\n",
    "    return diff\n",
    "\n",
    "A = [{'a': (1,1), 'b':(1,1)}, {'a': (2, 2), 'b':(2, 2)}, {'a': (3,3), 'b':(3,3)}, {'a': (4,), 'b':(4,4)}]\n",
    "a = [{'a': (1, 1), 'b':(1, 1)}, {'a': (2, 2), 'b':(2, 2)}]\n",
    "\n",
    "subtract_2list_set(A, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d12d115d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "a = (4, )\n",
    "for i in a: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aec51666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30 * 100 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "174952c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8064"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 * 7 * 2 * 3 * 3 * 4 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82296e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>feature_29</th>\n",
       "      <th>feature_30</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.844756</td>\n",
       "      <td>-0.533481</td>\n",
       "      <td>-0.206876</td>\n",
       "      <td>-0.389410</td>\n",
       "      <td>0.630029</td>\n",
       "      <td>-4.168175</td>\n",
       "      <td>-1.869518</td>\n",
       "      <td>1.133280</td>\n",
       "      <td>0.019865</td>\n",
       "      <td>1.395874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422654</td>\n",
       "      <td>3.485662</td>\n",
       "      <td>8.447453</td>\n",
       "      <td>-1.763685</td>\n",
       "      <td>-1.426273</td>\n",
       "      <td>-5.095484</td>\n",
       "      <td>-1.542831</td>\n",
       "      <td>1.004960</td>\n",
       "      <td>10.697746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.937130</td>\n",
       "      <td>-0.983859</td>\n",
       "      <td>1.179499</td>\n",
       "      <td>1.286829</td>\n",
       "      <td>5.103923</td>\n",
       "      <td>-0.980036</td>\n",
       "      <td>0.253056</td>\n",
       "      <td>0.840339</td>\n",
       "      <td>-0.356096</td>\n",
       "      <td>6.233236</td>\n",
       "      <td>...</td>\n",
       "      <td>3.074848</td>\n",
       "      <td>1.536606</td>\n",
       "      <td>11.938079</td>\n",
       "      <td>-1.801377</td>\n",
       "      <td>2.704300</td>\n",
       "      <td>4.075018</td>\n",
       "      <td>-0.397624</td>\n",
       "      <td>0.680828</td>\n",
       "      <td>-1.793988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.644894</td>\n",
       "      <td>1.125551</td>\n",
       "      <td>-0.196897</td>\n",
       "      <td>-3.617585</td>\n",
       "      <td>1.762593</td>\n",
       "      <td>1.892517</td>\n",
       "      <td>0.906742</td>\n",
       "      <td>-0.125487</td>\n",
       "      <td>-1.439211</td>\n",
       "      <td>0.041238</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.042147</td>\n",
       "      <td>-1.390093</td>\n",
       "      <td>-4.376811</td>\n",
       "      <td>2.721640</td>\n",
       "      <td>0.082337</td>\n",
       "      <td>1.056139</td>\n",
       "      <td>-2.297366</td>\n",
       "      <td>0.403869</td>\n",
       "      <td>-2.676472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.928558</td>\n",
       "      <td>-0.405701</td>\n",
       "      <td>-0.807169</td>\n",
       "      <td>-2.806899</td>\n",
       "      <td>0.558924</td>\n",
       "      <td>3.884006</td>\n",
       "      <td>-3.366074</td>\n",
       "      <td>1.025522</td>\n",
       "      <td>4.576766</td>\n",
       "      <td>1.256689</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.438162</td>\n",
       "      <td>-2.130731</td>\n",
       "      <td>-3.545424</td>\n",
       "      <td>-0.195679</td>\n",
       "      <td>4.421337</td>\n",
       "      <td>2.410799</td>\n",
       "      <td>3.382267</td>\n",
       "      <td>-0.499100</td>\n",
       "      <td>-10.073781</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.440733</td>\n",
       "      <td>-0.967820</td>\n",
       "      <td>-0.489022</td>\n",
       "      <td>-3.602032</td>\n",
       "      <td>1.216314</td>\n",
       "      <td>-2.537438</td>\n",
       "      <td>-2.278376</td>\n",
       "      <td>4.155401</td>\n",
       "      <td>0.730369</td>\n",
       "      <td>-6.008000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.214354</td>\n",
       "      <td>-0.863725</td>\n",
       "      <td>-6.158999</td>\n",
       "      <td>-3.042925</td>\n",
       "      <td>0.516383</td>\n",
       "      <td>2.554031</td>\n",
       "      <td>-3.617897</td>\n",
       "      <td>0.979617</td>\n",
       "      <td>0.081948</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0  -4.844756  -0.533481  -0.206876  -0.389410   0.630029  -4.168175   \n",
       "1  -1.937130  -0.983859   1.179499   1.286829   5.103923  -0.980036   \n",
       "2  -0.644894   1.125551  -0.196897  -3.617585   1.762593   1.892517   \n",
       "3  13.928558  -0.405701  -0.807169  -2.806899   0.558924   3.884006   \n",
       "4  -2.440733  -0.967820  -0.489022  -3.602032   1.216314  -2.537438   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_22  feature_23  \\\n",
       "0  -1.869518   1.133280   0.019865    1.395874  ...    0.422654    3.485662   \n",
       "1   0.253056   0.840339  -0.356096    6.233236  ...    3.074848    1.536606   \n",
       "2   0.906742  -0.125487  -1.439211    0.041238  ...   -1.042147   -1.390093   \n",
       "3  -3.366074   1.025522   4.576766    1.256689  ...   -1.438162   -2.130731   \n",
       "4  -2.278376   4.155401   0.730369   -6.008000  ...   -2.214354   -0.863725   \n",
       "\n",
       "   feature_24  feature_25  feature_26  feature_27  feature_28  feature_29  \\\n",
       "0    8.447453   -1.763685   -1.426273   -5.095484   -1.542831    1.004960   \n",
       "1   11.938079   -1.801377    2.704300    4.075018   -0.397624    0.680828   \n",
       "2   -4.376811    2.721640    0.082337    1.056139   -2.297366    0.403869   \n",
       "3   -3.545424   -0.195679    4.421337    2.410799    3.382267   -0.499100   \n",
       "4   -6.158999   -3.042925    0.516383    2.554031   -3.617897    0.979617   \n",
       "\n",
       "   feature_30  target  \n",
       "0   10.697746       0  \n",
       "1   -1.793988       0  \n",
       "2   -2.676472       0  \n",
       "3  -10.073781       1  \n",
       "4    0.081948       1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(\n",
    "    n_samples=100_000,      # 100,000 rows\n",
    "    n_features=30,          # 30 features\n",
    "    n_informative=20,       # 20 informative features\n",
    "    n_redundant=5,          # 5 redundant (correlated) features\n",
    "    n_repeated=0,           # no repeated features\n",
    "    n_classes=2,            # binary classification\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(X, columns=[f\"feature_{i+1}\" for i in range(X.shape[1])])\n",
    "df[\"target\"] = y  # Add target column\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0373c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import psutil\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Your model-creating function\n",
    "def create_model(param): \n",
    "    return RandomForestClassifier(**param)\n",
    "\n",
    "# Sample list of parameters\n",
    "list_param = [\n",
    "    {'n_estimators': 700, 'max_depth': 30},\n",
    "    {'n_estimators': 800, 'max_depth': 30},\n",
    "    {'n_estimators': 900, 'max_depth': 30},\n",
    "]\n",
    "\n",
    "# Your dataset\n",
    "df_features = df.drop(columns=['target'])\n",
    "df_target = df['target']\n",
    "\n",
    "# Helper to check current memory usage in MB\n",
    "def print_memory_usage(tag=\"\"):\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_mb = process.memory_info().rss / 1024 / 1024\n",
    "    print(f\"{tag} Memory usage: {mem_mb:.2f} MB\")\n",
    "\n",
    "# Train and clear memory after each model\n",
    "for i, param in enumerate(list_param): \n",
    "    print_memory_usage(f\"Before training model {i+1}\")\n",
    "    \n",
    "    model = create_model(param)\n",
    "    model.fit(df_features, df_target)\n",
    "\n",
    "    print_memory_usage(f\"After training model {i+1}\")\n",
    "\n",
    "    # Delete and clean up memory\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "    print_memory_usage(f\"After deleting model {i+1}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366be613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn models \n",
    "del model\n",
    "gc.collect()\n",
    "\n",
    "# xgb models \n",
    "model._Booster.free()  # Frees internal booster memory\n",
    "del model\n",
    "gc.collect()\n",
    "\n",
    "# lgbm \n",
    "model.booster_.free_dataset()\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_model_memory_on_RAM(model): \n",
    "    if isinstance(model, (XGBClassifier, XGBRegressor)):\n",
    "        model._Booster.free()  # Frees internal booster memory\n",
    "\n",
    "    if isinstance(model, (LGBMClassifier, LGBMRegressor)):\n",
    "        model.booster_.free_dataset()\n",
    "        \n",
    "    del model\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
